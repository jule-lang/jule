// Copyright 2024 The Jule Programming Language.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

// The scanner implementation and related functions (such as split functions)
// are inspired by the implementation of the Go programming language.
// There may be various changes in the algorithm. Optimized and adopted for Jule.

use "std/bytes"
use "std/io"
use "std/unicode/utf8"
use "std/unsafe"

// Error codes for scanner.
enum ScanError {
	TooLong,         // Token size exceeds the maximum token size limit.
	BadReadCount,    // The reader returned invalid read count.
	NegativeAdvance, // Advance value of the splitter function was negative.
	AdvanceTooFar,   // Advance value of the splitter function was too far.
	NoProgress,      // No progress for the scanning.
}

const maxConsecutiveEmptyReads = 100

// Size of initial allocation for buffer.
// Implementation may ignore this if maximum token size is smaller.
const startBufSize = 1 << 12

// The default maximum token size of the Scanner.
const MaxTokenSize = 1 << 16 // 64 * 1024

// The signature of the split function used to tokenize the
// input. The arguments are an initial substring of the remaining unprocessed
// data and a flag, atEOF, that reports whether the [Reader] has no more data
// to give. The return values are the number of bytes to advance the input
// and the next token to return to the user, if any. It throws error as
// exceptional, if any.
//
// Any exceptional scanning will stop and data may be lost. A successful read
// should always return successfully, any exceptional means it failed.
//
// Otherwise, the [Scanner] advances the input. If the token is not nil,
// the [Scanner] returns it to the user. If the token is nil, the
// [Scanner] reads more data and continues scanning; if there is no more
// data--if atEOF was true--the [Scanner] returns. If the data does not
// yet hold a complete token, for instance if it has no newline while
// scanning lines, a [SplitFunc] can return (0, nil) to signal the
// [Scanner] to read more data into the slice and try again with a
// longer slice starting at the same point in the input.
//
// The function is never called with an empty data slice unless atEOF
// is true. If atEOF is true, however, data may be non-empty and,
// as always, holds unprocessed text.
//
// The data is a mutable copy into the relevant range of the Scanner's
// internal buffer. It is considered mutable because it is considered legal
// for this function to return a mutable slice from the relevant data.
// However, mutating the data is definitely not recommended.
// A safe [SplitFunc] should handle data without mutating it.
type SplitFunc: fn(mut data: []byte, atEOF: bool)!: (advance: int, token: []byte)

// Scanner configuration data.
// All fields will assigned to the default value for the Scanner, for zero value.
struct ScannerCfg {
	Split: SplitFunc = SplitLines // The splitter function.
	Max:   int = MaxTokenSize     // The maximum token size.
}

// Provides a convenient interface for reading data such as
// a file of newline-delimited lines of text. Successive calls to
// the [Scanner.Scan] method will step through the 'tokens' of a file, skipping
// the bytes between the tokens. The specification of a token is
// defined by a split function of type [SplitFunc]; the default split
// function breaks the input into lines with line termination stripped.
// The split functions are defined in this package for scanning a file into
// lines, bytes, UTF-8-encoded runes, and space-delimited words. The
// client may instead provide a custom split function.
//
// Scanning stops unrecoverably at EOF, the first I/O error, or a token too
// large to fit in the buffer. When a scan stops, the reader may have
// advanced arbitrarily far past the last token.
struct Scanner {
	r:       io::Reader // The reader provided by the client.
	split:   SplitFunc  // The splitter function.
	max:     int        // The maximum token size.
	buf:     []byte     // Buffer used as argument to split.
	start:   int        // First non-processed byte in buf.
	end:     int        // End of data in buf.
	empties: int        // Count of successive empty tokens.
	atEOF:   bool       // Whether the reader at the EOF.
	mut tok: []byte     // The last readed token.
}

impl Scanner {
	// Returns new Scanner for r with the default configuration.
	static fn New(mut r: io::Reader): &Scanner {
		ret Scanner.NewCfg(r, {})
	}

	// Returns new Scanner for r by the custom configuration.
	static fn NewCfg(mut r: io::Reader, cfg: ScannerCfg): &Scanner {
		ret &Scanner{
			r: r,
			split: cfg.Split,
			max: cfg.Max,
		}
	}

	// Returns the most recent token generated by a call to [Scanner.Scan].
	// The underlying array may point to data that will be overwritten
	// by a subsequent call to Scan. It does no allocation.
	fn Token(mut self): []byte {
		ret self.tok
	}

	// Returns the most recent token generated by a call to [Scanner.Scan]
	// as a newly allocated string holding its bytes.
	fn Text(self): str {
		ret str(self.tok)
	}

	// Advances the [Scanner] to the next token, which will then be
	// available through the [Scanner.Token] or [Scanner.Text] method.
	// It returns false when there are no more tokens, either by reaching
	// the end of the input or an exceptional. After Scan returns false,
	// without any exceptional, it means EOF. Any exceptional will be forwarded.
	// Scan panics if the split function returns too many empty
	// tokens without advancing the input. This is a common error mode for
	// scanners.
	fn Scan(mut self)!: bool {
		// Loop until we have a token.
		for {
			// See if we can get a token with what we already have.
			if self.end > self.start || self.atEOF {
				advance, mut token := self.split(self.buf[self.start:self.end], self.atEOF) else { error(error) }
				if advance < 0 {
					error(ScanError.NegativeAdvance)
				}
				if advance > self.end-self.start {
					error(ScanError.AdvanceTooFar)
				}
				self.start += advance
				if token != nil {
					self.tok = token
					if advance > 0 {
						self.empties = 0
					} else {
						// Returning tokens not advancing input at EOF.
						self.empties++
						if self.empties > maxConsecutiveEmptyReads {
							panic("std/bufio: Scanner.Scan: too many empty tokens without progressing")
						}
					}
					ret true
				}
				if self.atEOF {
					// We have EOF state and the split function will not return
					// token for this case, guaranteed for the false return.
					ret false
				}
			}
			// Must read more data.
			// First, shift data to beginning of buffer if there's lots of empty space
			// or space is needed.
			if self.start > 0 &&
				(self.end == len(self.buf) || self.start > len(self.buf)/2) {
				copy(self.buf, self.buf[self.start:self.end])
				self.end -= self.start
				self.start = 0
			}
			// Is the buffer full? so, resize.
			if self.end >= len(self.buf) {
				// Guarantee no overflow in the multiplication below.
				const maxInt = int(^uint(0) >> 1)
				if len(self.buf) >= self.max || len(self.buf) > maxInt/2 {
					error(ScanError.TooLong)
				}
				mut newSize := len(self.buf) << 1
				if newSize == 0 {
					newSize = startBufSize
				}
				if self.max < newSize {
					newSize = self.max
				}
				mut newBuf := make([]byte, newSize)
				copy(newBuf, self.buf[self.start:self.end])
				self.buf = newBuf
				self.start = 0
			}
			// Finally we can read some input
			n := self.r.Read(self.buf[self.end:]) else { error(error) }
			if n < 0 || len(self.buf)-self.end < n {
				error(ScanError.BadReadCount)
			}
			if n == 0 {
				// Read buffer should not be empty.
				// So, by documentation of the io::Reader,
				// the zero read count means EOF.
				self.atEOF = true
				// If there is data in the buffer, give the splitter function
				// a chance to handle data with EOF state. So, do not return here.
				// Let next iteration step handle this case.
				continue
			}
			self.end += n
		}
	}
}

// Drops a terminal \r from the data.
fn dropCR(mut data: []byte): []byte {
	if len(data) > 0 && data[len(data)-1] == '\r' {
		ret data[0:len(data)-1]
	}
	ret data
}

// The split function for a [Scanner] that returns each line of text,
// stripped of any trailing end-of-line marker. The returned line may
// be empty. The end-of-line marker is one optional carriage return followed
// by one mandatory newline. In regular expression notation, it is `\r?\n`.
// The last non-empty line of input will be returned even if it has no
// newline.
fn SplitLines(mut data: []byte, atEOF: bool)!: (advance: int, token: []byte) {
	if atEOF && len(data) == 0 {
		ret 0, nil
	}
	i := bytes::IndexByte(data, '\n')
	if i >= 0 {
		// We have a full newline-terminated line.
		ret i + 1, dropCR(data[:i])
	}
	// If we're at EOF, we have a final, non-terminated line. Return it.
	if atEOF {
		ret len(data), dropCR(data)
	}
	// Request more data.
	ret 0, nil
}

// The split function for a [Scanner] that returns each byte as a token.
fn ScanBytes(mut data: []byte, atEOF: bool)!: (advance: int, token: []byte) {
	if atEOF && len(data) == 0 {
		ret 0, nil
	}
	ret 1, data[:1]
}

// Reports whether the character is a Unicode white space character.
// We avoid dependency on the unicode package, but check validity of the implementation
// in the tests.
fn isSpace(r: rune): bool {
	if r <= '\u00FF' {
		// Obvious ASCII ones: \t through \r plus space. Plus two Latin-1 oddballs.
		match r {
		| ' ' | '\t' | '\n' | '\v' | '\f' | '\r':
			ret true
		| '\u0085' | '\u00A0':
			ret true
		}
		ret false
	}
	// High-valued ones.
	if '\u2000' <= r && r <= '\u200a' {
		ret true
	}
	ret r == '\u1680' ||
		r == '\u2028' ||
		r == '\u2029' ||
		r == '\u202f' ||
		r == '\u205f' ||
		r == '\u3000'
}

// The split function for a [Scanner] that returns each space-separated word of text,
// with surrounding spaces deleted. It will never return an empty string.
// The definition of space is set by unicode::IsSpace.
fn ScanWords(mut data: []byte, atEOF: bool)!: (advance: int, token: []byte) {
	// Skip leading spaces.
	mut start := 0
	mut width := 0
	for start < len(data); start += width {
		mut r := rune(0)
		r, width = utf8::DecodeRune(data[start:])
		if !isSpace(r) {
			break
		}
	}
	// Scan until space, marking end of word.
	width = 0
	mut i := start
	for i < len(data); i += width {
		mut r := rune(0)
		r, width = utf8::DecodeRune(data[i:])
		if isSpace(r) {
			ret i + width, data[start:i]
		}
	}
	// If we're at EOF, we have a final, non-empty, non-terminated word. Return it.
	if atEOF && len(data) > start {
		ret len(data), data[start:]
	}
	// Request more data.
	ret start, nil
}

// ScanRunes is a split function for a [Scanner] that returns each
// UTF-8-encoded rune as a token. The sequence of runes returned is
// equivalent to that from a range loop over the input as a string, which
// means that erroneous UTF-8 encodings translate to U+FFFD = "\xef\xbf\xbd".
// Because of the Scan interface, this makes it impossible for the client to
// distinguish correctly encoded replacement runes from encoding errors.
fn ScanRunes(mut data: []byte, atEOF: bool)!: (advance: int, token: []byte) {
	if atEOF && len(data) == 0 {
		ret 0, nil
	}

	// Fast path 1: ASCII.
	if data[0] < utf8::RuneSelf {
		ret 1, data[0:1]
	}

	// Fast path 2: Correct UTF-8 decode without error.
	_, width := utf8::DecodeRune(data)
	if width > 1 {
		// It's a valid encoding. Width cannot be one for a correctly encoded
		// non-ASCII rune.
		ret width, data[0:width]
	}

	// We know it's an error: we have width==1 and implicitly r==utf8.RuneError.
	// Is the error because there wasn't a full rune to be decoded?
	// FullRune distinguishes correctly between erroneous and incomplete encodings.
	if !atEOF && !utf8::FullRune(data) {
		// Incomplete; get more bytes.
		ret 0, nil
	}

	// We have a real UTF-8 encoding error. Return a properly encoded error rune
	// but advance only one byte. This matches the behavior of a range loop over
	// an incorrectly encoded string.
	mut errorRune := []byte(str(utf8::RuneError))
	ret 1, errorRune
}