// Copyright 2023-2024 The Jule Programming Language.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

use std::jule::build::{Logf, LogMsg, Log, LogKind}
use std::internal::strings::{StrBuilder}
use utf8 for std::unicode::utf8

// Lexer mode.
enum LexMode {
    Standard: 0 << 0, // Standard mode.
    Comment: 1 << 0,  // Standard mode + comments.
}

struct kindPair {
    kind: TokenKind
    id:   TokenId
}

static keywords: [...]kindPair = [
    {TokenKind.Const, TokenId.Const},
    {TokenKind.Ret, TokenId.Ret},
    {TokenKind.Type, TokenId.Type},
    {TokenKind.For, TokenId.For},
    {TokenKind.Break, TokenId.Break},
    {TokenKind.Cont, TokenId.Cont},
    {TokenKind.In, TokenId.In},
    {TokenKind.If, TokenId.If},
    {TokenKind.Else, TokenId.Else},
    {TokenKind.Use, TokenId.Use},
    {TokenKind.Goto, TokenId.Goto},
    {TokenKind.Enum, TokenId.Enum},
    {TokenKind.Struct, TokenId.Struct},
    {TokenKind.Co, TokenId.Co},
    {TokenKind.Match, TokenId.Match},
    {TokenKind.Self, TokenId.Self},
    {TokenKind.Trait, TokenId.Trait},
    {TokenKind.Impl, TokenId.Impl},
    {TokenKind.Cpp, TokenId.Cpp},
    {TokenKind.Fall, TokenId.Fall},
    {TokenKind.Fn, TokenId.Fn},
    {TokenKind.Let, TokenId.Let},
    {TokenKind.Unsafe, TokenId.Unsafe},
    {TokenKind.Mut, TokenId.Mut},
    {TokenKind.Defer, TokenId.Defer},
    {TokenKind.Static, TokenId.Static},
    {TokenKind.Error, TokenId.Error},
    {TokenKind.Map, TokenId.Map},
]

static basicOps: [...]kindPair = [
    {TokenKind.DblColon, TokenId.DblColon},
    {TokenKind.ColonEq, TokenId.ColonEq},
    {TokenKind.Colon, TokenId.Colon},
    {TokenKind.Semicolon, TokenId.Semicolon},
    {TokenKind.Comma, TokenId.Comma},
    {TokenKind.TripleDot, TokenId.TripleDot},
    {TokenKind.Dot, TokenId.Dot},
    {TokenKind.PlusEq, TokenId.PlusEq},
    {TokenKind.MinusEq, TokenId.MinusEq},
    {TokenKind.StarEq, TokenId.StarEq},
    {TokenKind.SolidusEq, TokenId.SolidusEq},
    {TokenKind.PercentEq, TokenId.PercentEq},
    {TokenKind.LshiftEq, TokenId.LshiftEq},
    {TokenKind.RshiftEq, TokenId.RshiftEq},
    {TokenKind.CaretEq, TokenId.CaretEq},
    {TokenKind.AmperEq, TokenId.AmperEq},
    {TokenKind.VlineEq, TokenId.VlineEq},
    {TokenKind.Eqs, TokenId.Eqs},
    {TokenKind.NotEq, TokenId.NotEq},
    {TokenKind.GreatEq, TokenId.GreatEq},
    {TokenKind.LessEq, TokenId.LessEq},
    {TokenKind.DblAmper, TokenId.DblAmper},
    {TokenKind.DblVline, TokenId.DblVline},
    {TokenKind.Lshift, TokenId.Lshift},
    {TokenKind.Rshift, TokenId.Rshift},
    {TokenKind.DblPlus, TokenId.DblPlus},
    {TokenKind.DblMinus, TokenId.DblMinus},
    {TokenKind.Plus, TokenId.Plus},
    {TokenKind.Minus, TokenId.Minus},
    {TokenKind.Star, TokenId.Star},
    {TokenKind.Solidus, TokenId.Solidus},
    {TokenKind.Percent, TokenId.Percent},
    {TokenKind.Amper, TokenId.Amper},
    {TokenKind.Vline, TokenId.Vline},
    {TokenKind.Caret, TokenId.Caret},
    {TokenKind.Excl, TokenId.Excl},
    {TokenKind.Lt, TokenId.Lt},
    {TokenKind.Gt, TokenId.Gt},
    {TokenKind.Eq, TokenId.Eq},
    {TokenKind.Hash, TokenId.Hash},
    {TokenKind.LBrace, TokenId.LBrace},
    {TokenKind.RBrace, TokenId.RBrace},
    {TokenKind.LBracket, TokenId.LBracket},
    {TokenKind.RBracket, TokenId.RBracket},
    {TokenKind.LParent, TokenId.LParent},
    {TokenKind.RParent, TokenId.RParent},
]

fn makeErr(row: int, col: int, &f: &File, fmt: LogMsg, args: ...any): Log {
    ret Log{
        Kind: LogKind.Error,
        Row: row,
        Column: col,
        Path: f.Path,
        Text: Logf(fmt, args...),
    }
}

fn bytesHasPrefix(&bytes: []byte, prefix: str): bool {
    if len(bytes) < len(prefix) {
        ret false
    }
    for i in prefix {
        if bytes[i] != prefix[i] {
            ret false
        }
    }
    ret true
}

fn floatFmtE(&txt: []byte, mut i: int): (lit: str) {
    i++ // Skip E | e
    if i >= len(txt) {
        ret
    }

    mut b := txt[i]
    if b == '_' {
        ret
    }
    if b == '+' || b == '-' {
        i++ // Skip operator
        if i >= len(txt) {
            ret
        }
        if txt[i] == '_' {
            ret
        }
    }

    first := i
    for i < len(txt); i++ {
        b = txt[i]
        if b != '_' && !IsDecimal(b) {
            break
        }
    }

    if i == first {
        ret ""
    }
    ret str(txt[:i])
}

fn floatFmtP(&txt: []byte, i: int): str {
    ret floatFmtE(txt, i)
}

fn floatFmtDotnp(&txt: []byte, mut i: int): str {
    if txt[i] != '.' {
        ret ""
    }

    i++
loop:
    for i < len(txt); i++ {
        b := txt[i]
        match {
        | b == '_' | IsDecimal(b):
            continue
        | isFloatFmtP(b, i):
            ret floatFmtP(txt, i)
        |:
            break loop
        }
    }
    ret ""
}

fn floatFmtDotfp(&txt: []byte, mut i: int): str {
    i += 2 // skip .f
    ret floatFmtE(txt, i)
}

fn floatFmtDotp(&txt: []byte, mut i: int): str {
    i++ // skip .
    ret floatFmtE(txt, i)
}

fn floatNum(&txt: []byte, mut i: int): (lit: str) {
    i++ // Skip dot
    if i >= len(txt) {
        ret str(txt)
    }
    if txt[i] == '_' {
        i--
        ret str(txt[:i])
    }
    for i < len(txt); i++ {
        b := txt[i]
        if i > 1 && (b == 'e' || b == 'E') {
            ret floatFmtE(txt, i)
        }
        if b != '_' && !IsDecimal(b) {
            break
        }
    }

    if i == 1 { // Just dot
        ret
    }
    ret str(txt[:i])
}

fn commonNum(&txt: []byte): (lit: str) {
    mut i := 0
loop:
    for i < len(txt); i++ {
        b := txt[i]
        match {
        | b == '.':
            ret floatNum(txt, i)
        | b == '_':
            continue
        | isFloatFmtE(b, i):
            ret floatFmtE(txt, i)
        | !IsDecimal(b):
            break loop
        }
    }

    if i == 0 {
        ret
    }
    ret str(txt[:i])
}

fn binaryNum(&txt: []byte): (lit: str) {
    if !bytesHasPrefix(txt, "0b") {
        ret ""
    }
    if len(txt) < 2 {
        ret
    }

    const BinaryStart = 2
    mut i := BinaryStart
    for i < len(txt); i++ {
        if txt[i] != '_' && !IsBinary(txt[i]) {
            break
        }
    }

    if i == BinaryStart {
        ret
    }
    ret str(txt[:i])
}

fn isFloatFmtE(b: byte, i: int): bool {
    ret i > 0 && (b == 'e' || b == 'E')
}

fn isFloatFmtP(b: byte, i: int): bool {
    ret i > 0 && (b == 'p' || b == 'P')
}

fn isFloatFmtDotnp(&txt: []byte, mut i: int): bool {
    if txt[i] != '.' {
        ret false
    }
    i++
loop:
    for i < len(txt); i++ {
        b := txt[i]
        match {
        | b == '_' | IsDecimal(b):
            continue
        | isFloatFmtP(b, i):
            ret true
        |:
            break loop
        }
    }

    ret false
}

fn isFloatFmtDotp(&txt: []byte, i: int): bool {
    match {
    | len(txt) < 3:
        fall
    | txt[i] != '.':
        fall
    | txt[i+1] != 'p' && txt[i+1] != 'P':
        ret false
    |:
        ret true
    }
}

fn isFloatFmtDotfp(&txt: []byte, i: int): bool {
    match {
    | len(txt) < 4:
        fall
    | txt[i] != '.':
        fall
    | txt[i+1] != 'f' && txt[i+1] != 'F':
        fall
    | txt[i+2] != 'p' && txt[i+1] != 'P':
        ret false
    |:
        ret true
    }
}

fn octalNum(&txt: []byte): (lit: str) {
    if txt[0] != '0' {
        ret ""
    }
    if len(txt) < 2 {
        ret
    }

    mut octalStart := 1

    mut o := false
    if txt[1] == 'o' {
        if len(txt) < 3 {
            ret
        }
        octalStart++
        o = true
    }

    mut i := octalStart
    for i < len(txt); i++ {
        b := txt[i]
        if b == '.' {
            if o {
                ret ""
            }
            ret floatNum(txt, i)
        }
        if isFloatFmtE(b, i) {
            ret floatFmtE(txt, i)
        }
        if b != '_' && !IsOctal(b) {
            break
        }
    }

    if i == octalStart {
        ret
    }
    ret str(txt[:i])
}

fn hexNum(&txt: []byte): (lit: str) {
    if len(txt) < 3 {
        ret
    }
    if txt[0] != '0' || (txt[1] != 'x' && txt[1] != 'X') {
        ret
    }

    const HexStart = 2
    mut i := HexStart
loop:
    for i < len(txt); i++ {
        b := txt[i]
        match {
        | isFloatFmtDotp(txt, i):
            ret floatFmtDotp(txt, i)
        | isFloatFmtDotfp(txt, i):
            ret floatFmtDotfp(txt, i)
        | isFloatFmtP(b, i):
            ret floatFmtP(txt, i)
        | isFloatFmtDotnp(txt, i):
            ret floatFmtDotnp(txt, i)
        | b != '_' && !IsHex(b):
            break loop
        }
    }

    if i == HexStart {
        ret
    }
    ret str(txt[:i])
}

fn hexEscape(&txt: []byte, n: int): (seq: str) {
    if len(txt) < n {
        ret
    }

    const HexStart = 2
    mut i := HexStart
    for i < n; i++ {
        if !IsHex(txt[i]) {
            ret
        }
    }

    seq = str(txt[:n])
    ret
}

// Pattern (RegEx): ^\\U.{8}
fn bigUnicodePointEscape(&txt: []byte): str {
    ret hexEscape(txt, 10)
}

// Pattern (RegEx): ^\\u.{4}
fn littleUnicodePointEscape(&txt: []byte): str {
    ret hexEscape(txt, 6)
}

// Pattern (RegEx): ^\\x..
fn hexByteEscape(&txt: []byte): str {
    ret hexEscape(txt, 4)
}

// Patter (RegEx): ^\\[0-7]{3}
fn byteEscape(&txt: []byte): (seq: str) {
    if len(txt) < 4 {
        ret
    }
    if !IsOctal(txt[1]) || !IsOctal(txt[2]) || !IsOctal(txt[3]) {
        ret
    }
    ret str(txt[:4])
}

struct lex {
    mode:   LexMode
    tokens: []&Token
    file:   &File
    pos:    int
    column: int
    row:    int
    errors: []Log
}

impl lex {
    fn pushErr(mut self, fmt: LogMsg, args: ...any) {
        self.errors = append(self.errors,
            makeErr(self.row, self.column, self.file, fmt, args...))
    }

    fn pushErrTok(mut self, &token: &Token, fmt: LogMsg) {
        self.errors = append(self.errors,
            makeErr(token.Row, token.Column, self.file, fmt))
    }

    // Lexs all source content.
    fn lex(mut self) {
        self.errors = nil
        self.newLine()
        for self.pos < len(self.file.Data) {
            mut token := self.token()
            if token.Id != TokenId.Na {
                self.tokens = append(self.tokens, token)
            }
        }
    }

    // Returns identifer if next token is identifer,
    // returns empty string if not.
    fn id(mut self, &ln: []byte): str {
        if len(ln) == 0 {
            ret ""
        }
        r, mut i := utf8::DecodeRune(ln)
        if r != '_' && !IsLetter(r) {
            ret ""
        }

        for i < len(ln) {
            pr, n := utf8::DecodeRune(ln[i:])
            if pr != '_' && !IsDecimal(byte(pr)) && !IsLetter(pr) {
                self.pos += i
                ret str(ln[:i])
            }
            i += n
        }

        self.pos += len(ln)
        ret str(ln)
    }

    // Resume to lex from position.
    fn resume(mut self): []byte {
        // Skip spaces.
        mut i := self.pos
        for i < len(self.file.Data); i++ {
            r := rune(self.file.Data[i])
            if IsSpace(r) {
                const TabLen = 8
                self.pos++
                match r {
                | '\n':
                    self.newLine()
                | '\t':
                    self.column += TabLen
                |:
                    self.column++
                }
                continue
            }

            mut j := i
            for j < len(self.file.Data); j++ {
                if self.file.Data[j] == '\n' {
                    break
                }
            }
            ret self.file.Data[i:j]
        }
        ret nil
    }

    fn lexLineComment(mut self, mut &token: &Token) {
        start := self.pos
        self.pos += 2
        for self.pos < len(self.file.Data); self.pos++ {
            r := self.file.Data[self.pos]
            if r == '\n' || r == '\r' {
                break
            }
        }
        if self.mode&LexMode.Comment == LexMode.Comment {
            token.Id = TokenId.Comment
            token.Kind = str(self.file.Data[start:self.pos])
        }
    }

    fn lexRangeComment(mut self, mut &token: &Token) {
        start := self.pos
        self.pos += 2
        for self.pos < len(self.file.Data); self.pos++ {
            r := self.file.Data[self.pos]
            if r == '\r' {
                continue
            }
            if r == '\n' {
                self.newLine()
                continue
            }
            self.column += 1
            if self.pos+1 < len(self.file.Data) && r == '*' &&
                self.file.Data[self.pos+1] == '/' {
                self.column += 2
                self.pos += 2
                if self.mode&LexMode.Comment == LexMode.Comment {
                    token.Id = TokenId.Comment
                    token.Kind = str(self.file.Data[start:self.pos])
                }
                ret
            }
        }
        self.pushErr(LogMsg.MissingBlockCommentClose)
    }

    // Returns literal if next token is numeric, returns empty string if not.
    fn num(mut self, &txt: []byte): (lit: str) {
        if txt[0] == '_' {
            ret ""
        }
        lit = hexNum(txt)
        if lit != "" {
            goto end
        }
        lit = octalNum(txt)
        if lit != "" {
            goto end
        }
        lit = binaryNum(txt)
        if lit != "" {
            goto end
        }
        lit = commonNum(txt)
    end:
        self.pos += len(lit)
        ret
    }

    fn escapeSeq(mut self, &txt: []byte): str {
        mut seq := ""
        if len(txt) < 2 {
            goto end
        }

        match txt[1] {
        | '\\' | '\'' | '"' | 'a' | 'b' | 'f' | 'n' | 'r' | 't' | 'v':
            self.pos += 2
            ret str(txt[:2])
        | 'U':
            seq = bigUnicodePointEscape(txt)
        | 'u':
            seq = littleUnicodePointEscape(txt)
        | 'x':
            seq = hexByteEscape(txt)
        |:
            seq = byteEscape(txt)
        }

    end:
        if seq == "" {
            self.pos++
            self.pushErr(LogMsg.InvalidEscapeSeq)
            ret ""
        }
        self.pos += len(seq)
        ret seq
    }

    fn getRune(mut self, &txt: []byte, raw: bool): str {
        if !raw && txt[0] == '\\' {
            ret self.escapeSeq(txt)
        }
        r, n := utf8::DecodeRune(txt)
        self.pos += n
        ret str(r)
    }

    fn lexRune(mut self, &txt: []byte): str {
        mut run := StrBuilder.New(1 << 3)
        run.WriteByte('\'')
        self.column++
        mut n := 0
        mut i := 1
        for i < len(txt); i++ {
            if txt[i] == '\r' {
                continue
            }
            if txt[i] == '\n' {
                self.pushErr(LogMsg.MissingRuneEnd)
                self.pos++
                self.newLine()
                ret ""
            }

            part := txt[i:]
            r := self.getRune(part, false)
            run.WriteStr(r)
            self.column += utf8::RuneCountStr(r)
            if r == "'" {
                self.pos++
                break
            }
            if len(r) > 1 {
                i += len(r) - 1
            }
            n++
        }

        if n == 0 {
            self.pushErr(LogMsg.RuneEmpty)
        } else if n > 1 {
            self.pushErr(LogMsg.RuneOverflow)
        }

        ret run.Str()
    }

    fn lexStr(mut self): str {
        mut s := StrBuilder.New(1 << 4)
        mark := self.file.Data[self.pos]
        self.pos++ // Skip mark
        raw := mark == '`'
        s.WriteByte(mark)
        self.column++

        for self.pos < len(self.file.Data) {
            ch := self.file.Data[self.pos]
            if ch == '\r' {
                continue
            }
            if ch == '\n' {
                self.newLine()
                if !raw {
                    self.pushErr(LogMsg.MissingStrEnd)
                    self.pos++
                    ret ""
                }
            }
            mut part := self.file.Data[self.pos:]
            r := self.getRune(part, raw)
            s.WriteStr(r)
            self.column += utf8::RuneCountStr(r)
            if ch == mark {
                break
            }
        }

        ret s.Str()
    }

    fn isFirstTokenOfLine(self): bool {
        ret self.column == 1
    }

    fn newLine(mut self) {
        self.row++
        self.column = 1
    }

    fn isOp(mut self, &txt: []byte, kind: str, id: TokenId, mut &t: &Token): bool {
        if !bytesHasPrefix(txt, kind) {
            ret false
        }
        t.Kind = kind
        t.Id = id
        self.pos += len(kind)
        ret true
    }

    fn lexBasicOps(mut self, txt: []byte, mut &tok: &Token): bool {
        for _, pair in basicOps {
            if self.isOp(txt, pair.kind, pair.id, tok) {
                ret true
            }
        }
        ret false
    }

    fn lexId(mut self, &txt: []byte, mut &t: &Token): bool {
        lex := self.id(txt)
        if lex == "" {
            ret false
        }
        t.Kind = lex
        t.Id = TokenId.Ident
        ret true
    }

    fn lexNum(mut self, &txt: []byte, mut &t: &Token): bool {
        lex := self.num(txt)
        if lex == "" {
            ret false
        }
        t.Kind = lex
        t.Id = TokenId.Lit
        ret true
    }

    // lex.Token generates next token from resume at position.
    fn token(mut self): &Token {
        mut t := &Token{
            File: self.file,
            Id: TokenId.Na,
        }

        txt := self.resume()
        if txt == nil {
            ret t
        }

        // Set token values.
        t.Column = self.column
        t.Row = self.row

        //* lex.Tokenenize
        match {
        | self.lexNum(txt, t):
            // Pass.
            break
        | txt[0] == '\'':
            t.Kind = self.lexRune(txt)
            t.Id = TokenId.Lit
            ret t
        | txt[0] == '"' || txt[0] == '`':
            t.Kind = self.lexStr()
            t.Id = TokenId.Lit
            ret t
        | bytesHasPrefix(txt, TokenKind.LnComment):
            self.lexLineComment(t)
            ret t
        | bytesHasPrefix(txt, TokenKind.RangLComment):
            self.lexRangeComment(t)
            ret t
        | self.lexBasicOps(txt, t):
            // Pass.
            break
        | self.lexId(txt, t):
            for _, pair in keywords {
                if pair.kind == t.Kind {
                    t.Id = pair.id
                    break
                }
            }
        |:
            r, sz := utf8::DecodeRune(txt)
            self.pushErr(LogMsg.InvalidToken, r)
            self.column++
            self.pos += sz
            ret t
        }
        self.column += utf8::RuneCountStr(t.Kind)
        ret t
    }
}

// Lex source code into fileset.
// Returns nil if f == nil.
// Returns nil slice for errors if no any error.
fn Lex(mut f: &File, mode: LexMode): []Log {
    if f == nil {
        ret nil
    }

    mut lex := lex{
        mode: mode,
        file: f,
        pos: 0,
        row: -1, // For true row 
    }

    lex.newLine()
    lex.lex()

    if len(lex.errors) > 0 {
        ret lex.errors
    }

    f.Tokens = lex.tokens
    ret nil
}