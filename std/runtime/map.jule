// Copyright 2024 The Jule Programming Language.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

// This file constains the source code of the built-in map type.
//
// Implementation adopted from Go port of the Abseil's SwissTable.
// Source repository: https://github.com/dolthub/swiss, commit [f4b2bab].
// But the implementation is not same as repository.
// Optimized for the Jule runtime and compiler.
//
//   Copyright 2024 The Jule Programming Language
//
//   Licensed under the Apache License, Version 2.0 (the "License");
//   you may not use this file except in compliance with the License.
//   You may obtain a copy of the License at
//
//       http://www.apache.org/licenses/LICENSE-2.0
//
//   Unless required by applicable law or agreed to in writing, software
//   distributed under the License is distributed on an "AS IS" BASIS,
//   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//   See the License for the specific language governing permissions and
//   limitations under the License.

use std::unsafe
use bits for std::math::bits
use binary for std::encoding::binary

const k0 = 0xc3a5c85c97cb3127
const k1 = 0xb492b66fbe98f273
const k2 = 0x9ae16a3b2f90404f
const c1 = 0xcc9e2d51
const c2 = 0x1b873593

struct u128 {
	hi: u64
	lo: u64
}

fn hash128to64(sum: u128): u64 {
	const kMul = 0x9ddfea08eb382d69
	mut a := (sum.lo ^ sum.hi) * kMul
	a ^= (a >> 47)
	mut b := (sum.hi ^ a) * kMul
	b ^= (b >> 47)
	b *= kMul
	ret b
}

fn fetch64(bytes: []byte): u64 { ret binary::LittleEndian.DecodeU64(bytes) }
fn fetch32(bytes: []byte): u32 { ret binary::LittleEndian.DecodeU32(bytes) }
fn shiftMix(z: u64): u64 { ret z ^ (z >> 47) }
fn hashLen16(u: u64, v: u64): u64 { ret hash128to64(u128{u, v}) }

fn rotate64(val: u64, shift: u32): u64 {
	// Avoid shifting by 64: doing so yields an undefined result.
	if shift != 0 {
		ret ((val >> shift) | (val << (64 - shift)))
	}
	ret val
}

fn hashLen16_3(u: u64, v: u64, mul: u64): u64 {
	mut a := (u ^ v) * mul
	a ^= (a >> 47)
	mut b := (v ^ a) * mul
	b ^= (b >> 47)
	b *= mul
	ret b
}

fn hashLen0to16(bytes: []byte, n: int): u64 {
	if n >= 8 {
		mul := k2 + u64(n)*2
		a := fetch64(bytes) + k2
		b := fetch64(bytes[n-8:])
		c := rotate64(b, 37)*mul + a
		d := (rotate64(a, 25) + b) * mul
		ret hashLen16_3(c, d, mul)
	}

	if n >= 4 {
		mul := k2 + u64(n)*2
		a := u64(fetch32(bytes))
		ret hashLen16_3(u64(n)+(a<<3), u64(fetch32(bytes[n-4:])), mul)
	}

	if n > 0 {
		a := u8(bytes[0])
		b := u8(bytes[n>>1])
		c := u8(bytes[n-1])
		y := u32(a) + (u32(b) << 8)
		z := n + (int(c) << 2)
		ret shiftMix(u64(y)*k2^u64(z)*k0) * k2
	}

	ret k2
}

fn hashMurmur(mut bytes: []byte, n: int, seed: u128): u128 {
	mut a := seed.lo
	mut b := seed.hi
	mut c := u64(0)
	mut d := u64(0)
	mut l := n - 16

	if l <= 0 { // len <= 16
		a = shiftMix(a*k1) * k1
		c = b*k1 + hashLen0to16(bytes, n)

		if n >= 8 {
			d = shiftMix(a + fetch64(bytes))
		} else {
			d = shiftMix(a + c)
		}
	} else { // len > 16
		c = hashLen16(fetch64(bytes[n-8:])+k1, a)
		d = hashLen16(b+u64(n), c+fetch64(bytes[n-16:]))
		a += d

		for {
			a ^= shiftMix(fetch64(bytes)*k1) * k1
			a *= k1
			b ^= a
			c ^= shiftMix(fetch64(bytes[8:])*k1) * k1
			c *= k1
			d ^= c
			bytes = bytes[16:]
			l -= 16

			if l <= 0 {
				break
			}
		}
	}

	a = hashLen16(a, c)
	b = hashLen16(d, b)
	ret u128{a ^ b, hashLen16(b, a)}
}

fn weakHashLen32WithSeeds(w: u64, x: u64, y: u64, z: u64, mut a: u64, mut b: u64): u128 {
	a += w
	b = rotate64(b+a+z, 21)
	c := a
	a += x
	a += y
	b += rotate64(a, 44)
	ret u128{a + z, b + c}
}

fn weakHashLen32WithSeeds_3(bytes: []byte, a: u64, b: u64): u128 {
	ret weakHashLen32WithSeeds(fetch64(bytes), fetch64(bytes[8:]),
		fetch64(bytes[16:]), fetch64(bytes[24:]), a, b)
}

fn hashWithSeed(mut bytes: []byte, mut n: int, seed: u128): u128 {
	if n < 128 {
		ret hashMurmur(bytes, n, seed)
	}
	rn := n
	t := bytes

	// We expect length >= 128 to be the common case.  Keep 56 bytes of state:
	// v, w, x, y, and z.
	let mut v: u128
	let mut w: u128
	mut x := seed.lo
	mut y := seed.hi
	mut z := u64(n) * k1

	v.lo = rotate64(y^k1, 49)*k1 + fetch64(bytes)
	v.hi = rotate64(v.lo, 42)*k1 + fetch64(bytes[8:])
	w.lo = rotate64(y+z, 35)*k1 + x
	w.hi = rotate64(x+fetch64(bytes[88:]), 53) * k1

	// This is the same inner loop as CityHash64(), manually unrolled.
	for {
		x = rotate64(x+y+v.lo+fetch64(bytes[8:]), 37) * k1
		y = rotate64(y+v.hi+fetch64(bytes[48:]), 42) * k1
		x ^= w.hi
		y += v.lo + fetch64(bytes[40:])
		z = rotate64(z+w.lo, 33) * k1
		v = weakHashLen32WithSeeds_3(bytes, v.hi*k1, x+w.lo)
		w = weakHashLen32WithSeeds_3(bytes[32:], z+w.hi, y+fetch64(bytes[16:]))
		z, x = x, z
		bytes = bytes[64:]
		x = rotate64(x+y+v.lo+fetch64(bytes[8:]), 37) * k1
		y = rotate64(y+v.hi+fetch64(bytes[48:]), 42) * k1
		x ^= w.hi
		y += v.lo + fetch64(bytes[40:])
		z = rotate64(z+w.lo, 33) * k1
		v = weakHashLen32WithSeeds_3(bytes, v.hi*k1, x+w.lo)
		w = weakHashLen32WithSeeds_3(bytes[32:], z+w.hi, y+fetch64(bytes[16:]))
		z, x = x, z
		bytes = bytes[64:]
		n -= 128
		if n < 128 {
			break
		}
	}

	x += rotate64(v.lo+z, 49) * k0
	y = y*k0 + rotate64(w.hi, 37)
	z = z*k0 + rotate64(w.lo, 27)
	w.lo *= 9
	v.lo *= k0

	// If 0 < length < 128, hash up to 4 chunks of 32 bytes each from the end of s.
	let mut tailDone = 0
	for tailDone < n {
		tailDone += 32
		y = rotate64(x+y, 42)*k0 + v.hi
		w.lo += fetch64(t[rn-tailDone+16:])
		x = x*k0 + w.lo
		z += w.hi + fetch64(t[rn-tailDone:])
		w.hi += v.lo
		v = weakHashLen32WithSeeds_3(t[rn-tailDone:], v.lo+z, v.hi)
		v.lo *= k0
	}

	// At this point our 56 bytes of state should contain more than
	// enough information for a strong 128-bit hash.  We use two
	// different 56-byte-to-8-byte hashes to get a 16-byte final result.
	x = hashLen16(x, v.lo)
	y = hashLen16(y+z, w.lo)

	ret u128{hashLen16(x+v.hi, w.hi) + y, hashLen16(x+w.hi, y+v.hi)}
}

// The hash function, designed for the built-in map type.
// This is basically 128-bit CityHash hash algorithm, converted to 64-bit after.
// The implementation adopted from the original Go code: https://github.com/zentures/cityhash/blob/master/cityhash.go, commit [cdd6a94].
// Comes with this license text:
//   The MIT License (MIT)
//   
//   Copyright (c) 2013 zhenjl
//   
//   Permission is hereby granted, free of charge, to any person obtaining a copy of
//   this software and associated documentation files (the "Software"), to deal in
//   the Software without restriction, including without limitation the rights to
//   use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
//   the Software, and to permit persons to whom the Software is furnished to do so,
//   subject to the following conditions:
//   
//   The above copyright notice and this permission notice shall be included in all
//   copies or substantial portions of the Software.
//   
//   THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
//   IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
//   FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
//   COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
//   IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
//   CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
fn hash(mut bytes: []byte): u64 {
	mut sum := u128{}
	if len(bytes) > 16 {
		sum = hashWithSeed(bytes[16:], len(bytes)-16,
			u128{fetch64(bytes), fetch64(bytes[8:]) + k0})
	} else {
		sum = hashWithSeed(bytes, len(bytes), u128{k0, k1})
	}
	ret hash128to64(sum)
}

const groupSize       = 8
const maxAvgGroupLoad = 4

const loBits = 0x0101010101010101
const hiBits = 0x8080808080808080

type bitset: u64

// h1 is a 57 bit hash prefix
type h1: u64

// h2 is a 7 bit hash suffix
type h2: i8

// metadata is the h2 metadata array for a group.
// find operations first probe the controls bytes
// to filter candidates before matching keys
type metadata: [groupSize]i8

unsafe fn metaMatchH2(m: *metadata, h: h2): bitset {
	// https://graphics.stanford.edu/~seander/bithacks.html##ValueInWord
	ret hasZeroByte(castU64(m) ^ (loBits * u64(h)))
}

unsafe fn metaMatchEmpty(m: *metadata): bitset {
	ret hasZeroByte(castU64(m) ^ hiBits)
}

fn nextMatch(mut &b: bitset): u32 {
	s := u32(bits::TrailingZeros64(u64(b)))
	b &= ^(1 << s) // clear bit |s|
	ret s >> 3   // div by 8
}

fn hasZeroByte(x: u64): bitset {
	ret bitset(((x - loBits) & ^(x)) & hiBits)
}

unsafe fn castU64(m: *metadata): u64 {
	ret unsafe { *(*u64)(m) }
}

// Returns the minimum number of groups needed to store |n| elems.
fn numGroups(n: int): (groups: int) {
	groups = (n + maxAvgGroupLoad - 1) / maxAvgGroupLoad
	if groups == 0 {
		groups = 1
	}
	ret
}

fn newEmptyMetadata(): (meta: metadata) {
	for i in meta {
		meta[i] = empty
	}
	ret
}

fn splitHash(h: u64): (h1, h2) {
	ret h1((h & h1Mask) >> 7), h2(h & h2Mask)
}

fn probeStart(hi: h1, groups: int): u32 {
	ret fastModN(u32(hi), u32(groups))
}

// lemire.me/blog/2016/06/27/a-fast-alternative-to-the-modulo-reduction/
fn fastModN(x: u32, n: u32): u32 {
	ret u32((u64(x) * u64(n)) >> 32)
}

const h1Mask    = 0xffff_ffff_ffff_ff80
const h2Mask    = 0x0000_0000_0000_007f
const empty     = -128 // 0b1000_0000
const tombstone = -2   // 0b1111_1110

// Default initial size of a map.
const mapInitialSize = 8

// group is a group of 16 key-value pairs
struct group[Key: comparable, Val] {
	keys:   [groupSize]Key
	values: [groupSize]Val
}

struct mapData[Key: comparable, Val] {
	ctrl:     []metadata
	groups:   []group[Key, Val]
	resident: int
	dead:     int
	limit:    int
}

// Built-in map type implementation. Typically it is a hashmap.
// It is not lock-free in terms of concurrency, that is,
// it does not offer a thread-safe implementation.
// Uses the [hash] function to hash keys.
// An empty initialization literal is valid and equals to nil map.
// It uses a internal pointer to achieve a pass-by-reference experience.
struct _Map[Key: comparable, Val] {
	data: &mapData[Key, Val]
}

impl _Map {
	// Reports whether map is nil.
	fn isNil(self): bool {
		ret self.data == nil
	}

	fn initData(mut self, cap: int) {
		self.data = new(mapData[Key, Val])
		groups := numGroups(cap)
		self.data.ctrl = make([]metadata, groups)
		self.data.groups = make([]group[Key, Val], groups)
		self.data.limit = groups * maxAvgGroupLoad
		for i in self.data.ctrl {
			self.data.ctrl[i] = newEmptyMetadata()
		}
	}

	// Returns hash for key.
	fn hash(self, k: Key): u64 {
		bytes := toStr(k)
		ret hash(unsafe::StrBytes(bytes))
	}

	fn rehash(mut self, n: int) {
		if self.isNil() {
			// no need for rehashing just handle nil data
			self.initData(mapInitialSize)
			ret
		}

		groups, ctrl := self.data.groups, self.data.ctrl
		self.data.groups = make([]group[Key, Val], n)
		self.data.ctrl = make([]metadata, n)
		for i in self.data.ctrl {
			self.data.ctrl[i] = newEmptyMetadata()
		}
		self.data.limit = n * maxAvgGroupLoad
		self.data.resident, self.data.dead = 0, 0
		for g in ctrl {
			for s in ctrl[g] {
				c := ctrl[g][s]
				if c == empty || c == tombstone {
					continue
				}
				unsafe { *self.set(groups[g].keys[s]) = groups[g].values[s] }
			}
		}
	}

	fn nextSize(self): (n: int) {
		if self.isNil() {
			ret mapInitialSize
		}
		n = len(self.data.groups) << 2
		if self.data.dead >= (self.data.resident >> 1) {
			n = len(self.data.groups)
		}
		ret
	}

	// Returns the |v| mapped by |k| if one exists.
	// Sets |v| if found and pointer not nil.
	// Same as the |ok| variable which reports whether |v| exist.
	unsafe fn lookup(mut self, mut k: Key, mut v: *Val, mut ok: *bool) {
		if self.isNil() {
			if ok != nil {
				*ok = false
			}
			ret
		}
		hi, lo := splitHash(self.hash(k))
		mut g := probeStart(hi, len(self.data.groups))
		for { // inlined find loop
			mut matches := unsafe { metaMatchH2(&self.data.ctrl[g], lo) }
			for matches != 0 {
				s := nextMatch(matches)
				if k == self.data.groups[g].keys[s] {
					if v != nil {
						*v = self.data.groups[g].values[s]
					}
					if ok != nil {
						*ok = true
					}
					ret
				}
			}
			// |k| is not in group |g|, stop probing if we see an empty slot
			matches = unsafe { metaMatchEmpty(&self.data.ctrl[g]) }
			if matches != 0 {
				if ok != nil {
					*ok = false
				}
				ret
			}
			g += 1 // linear probing
			if g >= u32(len(self.data.groups)) {
				g = 0
			}
		}
	}

	// Returns value of key if exist, otherwise returns default value of value type.
	fn get(mut self, mut k: Key): Val {
		let mut v: Val
		mut ok := false
		unsafe { self.lookup(k, &v, &ok) }
		ret v
	}

	// Attempts to insert |k|.
	// Returns pointer to value of inserted or already exist |k|.
	fn set(mut self, mut k: Key): (v: *Val) {
		if self.isNil() || self.data.resident >= self.data.limit {
			self.rehash(self.nextSize())
		}
		hi, lo := splitHash(self.hash(k))
		mut g := probeStart(hi, len(self.data.groups))
		for { // inlined find loop
			mut matches := unsafe { metaMatchH2(&self.data.ctrl[g], lo) }
			for matches != 0 {
				s := nextMatch(matches)
				if k == self.data.groups[g].keys[s] { // update
					self.data.groups[g].keys[s] = k
					v = &self.data.groups[g].values[s]
					ret
				}
			}
			// |k| is not in group |g|,
			// stop probing if we see an empty slot
			matches = unsafe { metaMatchEmpty(&self.data.ctrl[g]) }
			if matches != 0 { // insert
				s := nextMatch(matches)
				self.data.groups[g].keys[s] = k
				v = &self.data.groups[g].values[s]
				self.data.ctrl[g][s] = i8(lo)
				self.data.resident++
				ret
			}
			g += 1 // linear probing
			if g >= u32(len(self.data.groups)) {
				g = 0
			}
		}
	}

	// Attempts to remove |k|, returns true successful.
	fn del(mut self, mut k: Key): (ok: bool) {
		if self.isNil() {
			ret false
		}
		hi, lo := splitHash(self.hash(k))
		mut g := probeStart(hi, len(self.data.groups))
		for {
			mut matches := unsafe { metaMatchH2(&self.data.ctrl[g], lo) }
			for matches != 0 {
				s := nextMatch(matches)
				if k == self.data.groups[g].keys[s] {
					ok = true
					// optimization: if |self.ctrl[g]| contains any empty
					// metadata bytes, we can physically delete |k|
					// rather than placing a tombstone.
					// The observation is that any probes into group |g|
					// would already be terminated by the existing empty
					// slot, and therefore reclaiming slot |s| will not
					// cause premature termination of probes into |g|.
					if unsafe { metaMatchEmpty(&self.data.ctrl[g]) != 0 } {
						self.data.ctrl[g][s] = empty
						self.data.resident--
					} else {
						self.data.ctrl[g][s] = tombstone
						self.data.dead++
					}
					let mut key: Key
					let mut val: Val
					self.data.groups[g].keys[s] = key
					self.data.groups[g].values[s] = val
					ret
				}
			}
			// |key| is not in group |g|,
			// stop probing if we see an empty slot
			matches = unsafe { metaMatchEmpty(&self.data.ctrl[g]) }
			if matches != 0 { // |key| absent
				ok = false
				ret
			}
			g += 1 // linear probing
			if g >= u32(len(self.data.groups)) {
				g = 0
			}
		}
	}

	// Removes all elements from the Map.
	fn clear(mut self) {
		if self.isNil() {
			ret
		}
		for i, c in self.data.ctrl {
			for j in c {
				self.data.ctrl[i][j] = empty
			}
		}
		let mut k: Key
		let mut v: Val
		for i in self.data.groups {
			mut g := &self.data.groups[i]
			unsafe {
				for j in g.keys {
					g.keys[j] = k
					g.values[j] = v
				}
			}
		}
		self.data.resident, self.data.dead = 0, 0
	}

	// Returns the number of elements in the map.
	fn len(self): int { ret self.data.resident - self.data.dead }

	// Returns the number of additional elements
	// the can be added before resizing.
	fn cap(self): int { ret self.data.limit - self.data.resident }

	fn iterator(mut self): mapIterator[Key, Val] {
		mut iterator := mapIterator[Key, Val]{m: self}
		iterator.init()
		ret iterator
	}
}

// Iterates the elements of the map, returns pointer to the key and value.
// It guarantees that any key in the map will be visited only once, and
// for un-mutated maps, every key will be visited once. If the map is
// mutated during iteration, mutations will be reflected on return from
// iter, but the set of keys visited by iter is non-deterministic.
struct mapIterator[Key: comparable, Val] {
	m:      _Map[Key, Val]
	ctrl:   []metadata
	groups: []group[Key, Val]
	n:      int
	g:      int
	s:      int
}

impl mapIterator {
	fn init(mut self) {
		if !self.m.isNil() {
			// take a consistent view of the table in case
			// we rehash during iteration
			self.ctrl, self.groups = unsafe { self.m.data.ctrl, self.m.data.groups }
			// pick a random starting group
			self.g = randInt(u64(uintptr(&self)), len(self.groups))
		}
		self.n = 0
		self.s = 0
	}

	// Returns pointer to the key and value.
	// Returns nil pointer for both if iteration ended.
	fn next(mut self): (*Key, *Val) {
		for self.n < len(self.groups); self.n++ {
			ctrl := &self.ctrl[self.g]
			for self.s < len(unsafe { *ctrl }); self.s++ {
				c := unsafe { (*ctrl)[self.s] }
				if c == empty || c == tombstone {
					continue
				}
				mut k := &self.groups[self.g].keys[self.s]
				mut v := &self.groups[self.g].values[self.s]
				self.s++
				if self.s >= len(unsafe { *ctrl }) {
					self.n++
					self.s = 0
					self.g++
					if self.g >= len(self.groups) {
						self.g = 0
					}
				}
				ret k, v
			}
			self.g++
			self.s = 0
			if self.g >= len(self.groups) {
				self.g = 0
			}
		}
		ret nil, nil
	}
}

fn init() {
	_ = binary::LittleEndian.DecodeU64
	_ = binary::LittleEndian.DecodeU32
}