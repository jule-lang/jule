// Copyright 2024-2025 The Jule Programming Language.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

const fmutexSize = 32 // i32

// Simpler mutex implementation for elementary purposes.
struct fmutex {
	mut state: i32
}

impl fmutex {
	fn lock(self) {
		mut iter := 1
		for !self.tryLock() {
			iter <<= 1
			if iter < 1<<9 {
				sleep(1e6)
				iter = 0
			}
		}
	}

	fn unlock(self) {
		new := atomicAdd(self.state, -mutexLocked, atomicSeqCst)
		if new != 0 {
			panic("runtime: mutex: unlock of unlocked mutex")
		}
	}

	fn tryLock(self): bool {
		ret atomicCompareAndSwap(self.state, 0, mutexLocked, atomicSeqCst)
	}
}

const mutexLocked = 1 << 0
const mutexWoken = 1 << 1
const mutexStarving = 1 << 2
const mutexWaiterShift = 3

// Mutex fairness.
//
// Mutex can be in 2 modes of operations: normal and starvation.
// In normal mode waiters are queued in FIFO order, but a woken up waiter
// does not own the mutex and competes with new arriving threads over
// the ownership. New arriving threads have an advantage -- they are
// already running on CPU and there can be lots of them, so a woken up
// waiter has good chances of losing.  In such case it is queued at front
// of the wait queue. If a waiter fails to acquire the mutex for more than 1.1ms,
// it switches mutex to the starvation mode.
//
// In starvation mode ownership of the mutex is directly handed off from
// the unlocking thread to the waiter at the front of the queue.
// New arriving threads don't try to acquire the mutex even if it appears
// to be unlocked, and don't try to spin. Instead they queue themselves at
// the tail of the wait queue.
//
// If a waiter receives ownership of the mutex and sees that either
// (1) it is the last waiter in the queue, or (2) it waited for less than 1.1ms,
// it switches mutex back to normal operation mode.
//
// Normal mode has considerably better performance as a thread can acquire
// a mutex several times in a row even if there are blocked waiters.
// Starvation mode is important to prevent pathological cases of tail latency.
const starvationThresholdNs = 1_100_000

// Advanced mutex implementation for common and public use.
// See the [sync::Mutex] for documentation.
// This implementation derived from the original Go code,
// but it may work different paritially.
// For the original Go code, see the sync.Mutex of the Go stdlib.
struct mutex {
	mut state: i32
	mut sema:  u32
}

impl mutex {
	// Locks the mutex.
	// See the [sync::Mutex] for documentation.
	fn lock(self) {
		// Fast path: grab unlocked mutex.
		if atomicCompareAndSwap(self.state, 0, mutexLocked, atomicSeqCst) {
			ret
		}
		// Slow path (outlined so that the fast path may be inlined)
		self.lockSlow()
	}

	fn lockSlow(self) {
		let mut waitStartTime: u64
		mut starving := false
		mut awoke := false
		mut iter := 1
		mut old := self.state
		for {
			// Don't spin in starvation mode, ownership is handed off to waiters
			// so we won't be able to acquire the mutex anyway.
			if old&(mutexLocked|mutexStarving) == mutexLocked && iter < 1<<9 {
				// Active spinning makes sense.
				// Try to set mutexWoken flag to inform Unlock
				// to not wake other blocked threads.
				if !awoke && old&mutexWoken == 0 && old>>mutexWaiterShift != 0 {
					awoke = atomicCompareAndSwap(self.state, old, old|mutexWoken, atomicSeqCst)
				}
				iter <<= 1
				old = self.state
				continue
			}
			mut new := old
			// Don't try to acquire starving mutex, new arriving threads must queue.
			if old&mutexStarving == 0 {
				new |= mutexLocked
			}
			if old&(mutexLocked|mutexStarving) != 0 {
				new += 1 << mutexWaiterShift
			}
			// The current thread switches mutex to starvation mode.
			// But if the mutex is currently unlocked, don't do the switch.
			// Unlock expects that starving mutex has waiters, which will not
			// be true in this case.
			if starving && old&mutexLocked != 0 {
				new |= mutexStarving
			}
			if awoke {
				// The thread has been woken from sleep,
				// so we need to reset the flag in either case.
				if new&mutexWoken == 0 {
					panic("runtime: inconsistent mutex state")
				}
				new &= ^mutexWoken
			}
			if atomicCompareAndSwap(self.state, old, new, atomicSeqCst) {
				if old&(mutexLocked|mutexStarving) == 0 {
					break // locked the mutex with CAS
				}
				// If we were already waiting before, queue at the front of the queue.
				queueLifo := waitStartTime != 0
				if waitStartTime == 0 {
					waitStartTime = nanotime()
				}
				semacquire(self.sema, queueLifo, semaMutex)
				starving = starving || nanotime()-waitStartTime > starvationThresholdNs
				old = self.state
				if old&mutexStarving != 0 {
					// If this thread was woken and mutex is in starvation mode,
					// ownership was handed off to us but mutex is in somewhat
					// inconsistent state: mutexLocked is not set and we are still
					// accounted as waiter. Fix that.
					if old&(mutexLocked|mutexWoken) != 0 || old>>mutexWaiterShift == 0 {
						panic("runtime: inconsistent mutex state")
					}
					mut delta := i32(mutexLocked - 1<<mutexWaiterShift)
					if !starving || old>>mutexWaiterShift == 1 {
						// Exit starvation mode.
						// Critical to do it here and consider wait time.
						// Starvation mode is so inefficient, that two threads
						// can go lock-step infinitely once they switch mutex
						// to starvation mode.
						delta -= mutexStarving
					}
					atomicAdd(self.state, delta, atomicSeqCst)
					break
				}
				awoke = true
				iter = 1
			} else {
				old = self.state
			}
		}
	}

	// Tries to lock the mutex.
	// See the [sync::Mutex] for documentation.
	fn tryLock(self): bool {
		old := self.state
		if old&(mutexLocked|mutexStarving) != 0 {
			ret false
		}

		// There may be a thread waiting for the mutex, but we are
		// running now and can try to grab the mutex before that
		// thread wakes up.
		ret atomicCompareAndSwap(self.state, old, old|mutexLocked, atomicSeqCst)
	}

	// Unlocks the mutex.
	// See the [sync::Mutex] for documentation.
	fn unlock(self) {
		// Fast path: drop lock bit.
		new := atomicAdd(self.state, -mutexLocked, atomicSeqCst)
		if new != 0 {
			// Outlined slow path to may allow inlining the fast path.
			self.unlockSlow(new)
		}
	}

	fn unlockSlow(self, mut new: i32) {
		if (new+mutexLocked)&mutexLocked == 0 {
			panic("runtime: unlock of unlocked mutex")
		}
		if new&mutexStarving == 0 {
			mut old := new
			for {
				// If there are no waiters or a thread has already
				// been woken or grabbed the lock, no need to wake anyone.
				// In starvation mode ownership is directly handed off from unlocking
				// thread to the next waiter. We are not part of this chain,
				// since we did not observe mutexStarving when we unlocked the mutex above.
				// So get off the way.
				if old>>mutexWaiterShift == 0 || old&(mutexLocked|mutexWoken|mutexStarving) != 0 {
					ret
				}
				// Grab the right to wake someone.
				new = (old - 1<<mutexWaiterShift) | mutexWoken
				{
					if atomicCompareAndSwap(self.state, old, new, atomicSeqCst) {
						semrelease(self.sema)
						ret
					}
				}
				old = self.state
			}
		} else {
			// Starving mode: handoff mutex ownership to the next waiter,
			// so that the next waiter can start to run immediately.
			// Note: mutexLocked is not set, the waiter will set it after wakeup.
			// But mutex is still considered locked if mutexStarving is set,
			// so new coming thread won't acquire it.
			semrelease(self.sema)
		}
	}
}